# Neural Collaborative Filtering

https://arxiv.org/pdf/1708.05031

---

### 1. 문제 제기: Matrix Factorization (MF) 의 근본적 한계

추천 시스템의 대표적인 알고리즘인 **행렬 분해(Matrix Factorization, MF)**는 사용자와 아이템을 각각 잠재 벡터로 표현하고, 
이 둘의 inner product을 통해 상호작용 점수를 예측함.

그러나 내적 연산의 단순함이 모델의 표현력을 저해. 
내적은 잠재 벡터의 각 차원을 단순히 곱한 후 선형적으로 합산하는 방식인데, 
이는 각 잠재 요인이 서로 독립적이며 모두 동일한 가중치로 결합된다고 가정하는 것과 같음. 
-> 하지만 실제 사용자-아이템 간의 복잡한 상호작용은 이런 단순한 선형 관계로 표현하기 어려움.

<img width="567" height="245" alt="image" src="https://github.com/user-attachments/assets/df140f11-de7c-4ff6-9796-843e14a16ab0" />

> MF의 한계 때문에 이런 사용자 관계를 정확히 표현하지 못하는 문제가 발생

***

## 2. NCF: 새로운 패러다임의 제안

NCF는 이런 한계를 극복하기 위해, 고정된 내적 함수를 데이터로부터 상호작용 함수 자체를 학습하는 유연한 신경망 구조로 대체하는 일반화된 프레임워크를 제안

#### **NCF의 일반 프레임워크 구조**

<img width="502" height="289" alt="image" src="https://github.com/user-attachments/assets/87bcb405-ce4a-46fe-8f94-28b52aab8e3b" />

* **입력층 (Input Layer):** 사용자(u)와 아이템(i)의 ID를 입력받음. 순수한 협업 필터링을 위해 ID만 사용하며, 이는 원-핫 인코딩된 희소 벡터(sparse vector) 형태로 표현됨.
* **임베딩 층 (Embedding Layer):** 입력된 희소 벡터를 **밀집 벡터(Dense Vector)**로 변환하는 Fully Connected Layer
* **신경망 CF 층 (Neural CF Layers):** 임베딩된 두 잠재 벡터를 입력으로 받아 여러 신경망 층을 통과시키며 사용자-아이템 간의 상호작용을 모델링
* **출력층 (Output Layer):** 마지막 은닉층의 결과값을 받아 최종 예측 점수를 0과 1 사이의 확률값으로 출력

***

### 3. NCF 프레임워크의 세 가지 모델

NCF 프레임워크 하에서, 논문은 세 가지 구체적인 구현 모델을 제시함.

#### **1. 일반화 행렬 분해 (Generalized Matrix Factorization, GMF)**

GMF는 전통적인 MF를 NCF 프레임워크에 맞게 확장한 모델임.
* 사용자 임베딩 벡터와 아이템 임베딩 벡터를 요소별 곱(element-wise product)
* 이 결과를 가중치를 학습하는 출력층에 연결해서 각 잠재 요인의 중요도를 다르게 부여할 수 있음.
* 출력층의 활성화 함수로 Sigmoid 같은 비선형 함수를 사용해서 모델의 표현력을 높임 -> 선형적인 MF 모델을 비선형적으로 일반화하는 효과

#### **2. 다층 퍼셉트론 (Multi-Layer Perceptron, MLP)**

MLP는 딥러닝의 장점을 적극적으로 활용하는 모델임.
* 사용자와 아이템 임베딩 벡터를 **단순 연결(concatenate)**하여 하나의 긴 벡터로 만듦.
* 단순 연결만으로는 상호작용을 충분히 모델링할 수 없음 -> 그 위에 여러 은닉층을 쌓아 상호작용을 학습하는 게 필수적
* 활성화 함수로는 **ReLU(Rectified Linear Unit)**를 채택
  > ReLU는 그래디언트 소실 문제에 강하고, 희소 활성화를 유도해 과적합을 방지하는 데 더 효과적이기 때문.
* 네트워크 구조는 하위층이 넓고 상위층으로 갈수록 뉴런 수가 줄어드는 **타워(tower) 구조**를 사용

#### **3. 신경망 행렬 분해 (Neural Matrix Factorization, NeuMF)**

NeuMF는 이 논문의 최종 제안 모델로, GMF의 선형적 특징 포착 능력과 MLP의 비선형적 특징 포착 능력을 융합한 모델.
* **유연한 융합 구조:** GMF와 MLP가 임베딩 층을 공유하지 않고 각각 독립적인 임베딩을 학습 -> 모델의 유연성과 성능을 극대화함
* **결합 방식:** 각각의 경로를 통과한 GMF와 MLP의 출력 벡터를 마지막 단계에서 concat한 후, 최종 예측을 위한 로지스틱 회귀 층을 통과시킴
* **사전 학습:** NeuMF의 목적 함수는 non-convex 형태라 초기값에 민감함.
  -> 성능과 수렴 안정성을 높이기 위해, 잘 학습된 GMF와 MLP 모델의 가중치로 NeuMF를 초기화하는 전략을 사용
    * GMF와 MLP를 각각 Adam 옵티마이저로 수렴할 때까지 학습시킴.
    * 학습된 파라미터를 NeuMF의 해당 부분에 복사해 초기화하고, Adam이 아닌 일반 SGD 옵티마이저로 전체 모델을 fine-tuning함

***

### 4. 학습 전략과 실험 결과

#### **학습 패러다임: 이진 분류로서의 추천**

이 논문은 암시적 피드백 데이터의 특성을 고려하여, 추천을 이진 분류 문제로 재정의함.
* **목적 함수:** 관측된 상호작용과 관측되지 않은 상호작용을 분류하는 문제로 보고, 이에 적합한 **이진 교차 엔트로피(로그 손실)**를 목적 함수로 사용함. 이는 제곱 오차보다 이진적인 데이터 특성에 더 잘 부합함.
* **네거티브 샘플링:** 실제 상호작용이 없는 '부정적' 데이터가 없기 때문에, 각 긍정적 상호작용에 대해 사용자가 상호작용하지 않은 아이템 중에서 일정 비율로 무작위 샘플링하여 학습에 사용함.

#### **주요 실험 결과**

<img width="839" height="442" alt="image" src="https://github.com/user-attachments/assets/d5671761-7641-4f83-88dd-6c1207f6e1b4" />

* **(RQ1) 성능:** NeuMF는 두 데이터셋에서 BPR, eALS 등 기존 최고 성능의 MF 기반 모델들을 모든 평가지표에서 통계적으로 유의미하게 능가했음.
* **(RQ2) 학습 프레임워크의 유효성:** 쌍별 순위 손실을 사용하는 BPR보다 로그 손실을 사용하는 GMF의 성능이 더 높았음. 또한, 긍정 샘플 1개당 3~6개의 부정 샘플을 사용할 때 최적의 성능을 보였음.
* **(RQ3) 딥러닝의 효과:** MLP 모델의 은닉층 수를 0개에서 4개로 늘려감에 따라 추천 성능이 꾸준히 향상되었음. 특히, 은닉층이 없는 모델은 비개인화 모델보다도 성능이 낮았는데, 이는 임베딩을 연결하는 것을 넘어 은닉층을 통해 상호작용을 학습하는 과정이 필수적임을 증명함.
* **사전 학습의 유용성:** 사전 학습을 적용한 NeuMF가 무작위로 초기화된 NeuMF보다 전반적으로 더 높은 성능을 보여, 제안된 초기화 전략의 효과를 입증했음.
